[["index.html", "Bibliografie 1 Portfolio", " Bibliografie Wouter 2024-06-25 1 Portfolio Hallo! ik ben Wouter Verra, Afgestudeerd met een bachelor biologisch en medisch laboratorium onderzoek met een minor in data science, een honours project werkende met de minION (DNA sequencing) en een stage met als doel het opzetten van een geoptimaliseerde pipeline voor het classificering van bacterien vanuit een huidmicrobioom. Deze site bevat mijn cv en een aantal voorbeelden van wat ik kan qua coderen en bioinformatica. "],["cv-wouter-verra.html", "2 CV Wouter Verra", " 2 CV Wouter Verra Algemene informatie Naam: Wouter Verra Adres: - Telefoonnummer: - E-mailadres: - Geboortedatum: 10 April 1996 Geslacht: Man Nationaliteit: Nederlandse Burgerlijke staat: Ongehuwd Opleidingen: Biologisch en Medisch Laboratorium Onderzoek te Utrecht, september 2018 tot maart 2024 Keltische Talen en Cultuur te Utrecht, september 2016 tot mei 2016 University Foundation Year (afgerond) Education First te Oxford, September 2015 tot mei 2016 VWO (afgerond) Marecollege te Leiden, September 2007 tot juni 2015 Werkervaring: Leiden Centre for Applied Bioinformatics, Bioinformatica en laborant stagair, februari 2023 tot december 2023 Hadro techniek, assemblage medewerker, september 2017 tot augustus 2018 Van Vliet The Candy Company, orderpicker, juni 2017 tot september 2017 Mc Donalds Bodegraven, crewlid, mei 2016 tot juni 2017 Vaardigheden: Programeertalen: R Bash Programmas: Rstudio Excel SPSS Talen: Nederlands (moedertaal) Engels (vloeiend) Hobbys: Bordspellen Boulderen "],["project-noldus.html", "3 Project Noldus", " 3 Project Noldus Samen met twee anderen heb ik een project uitgevoerd voor het bedrijf Noldus About Noldus - Innovative Solutions Noldus (n.d.). Dit is een bedrijf dat zich specialiseert in het maken van producten voor gedragsonderzoek. Een paar voorbeelden hiervan zijn de UltraVox XT Rodent Ultrasonic Vocalizations UltraVox XT (n.d.) welke de geluiden die knaagdieren maken analyseert, FaceReader Facial Expression Recognition Software FaceReader (n.d.) welke menselijke gezichtsuitdrukkingen analyseert en de Erasmus ladder Motor Performance and Motor Learning ErasmusLadder (n.d.). De laatste was de focus van dit project. De Erasmus ladder bestaat uit twee hokken met een horizontale ladder er tussen. De muizen worden overgehaald uit het hokje te gaan door een luchtstroom en lichtjes waarna het leert dat als het naar de overkant loopt de wind en lichtjes stoppen, het wil dus zo snel mogelijk naar de overkant. De tred waarmee de muis loopt zegt iets over hoe goed de motor functie is van de muis en daarmee kan gekwantificeerd worden hoe erg de muis is beinvloed door de experimentele conditie Motor Function &amp; Gait Analysis Mouse Models (n.d.). De ladder heeft treden waar een knop onder zit waardoor er gemeten kan worden wat voor soort stap er gezet is en voor hoe lang. Er zijn 4 soorten stappen die gezet kunnen worden, namelijk: korte stap, lange stap, sprong en terug stap en deze informatie wordt allemaal per experiment opgeslagen inclusief de volgorde van de soort stappen per muis. Dit wordt opgeslagen in een grote Excel file met nog veel meer variabelen en metadata per muis zoals leeftijd en sekse. Deze data wordt ingeladen in R, waarna er veel verschillende grafieken mee gemaakt konden worden. Noldus wou graag hun data visualisatie verbeteren, dit werd toen der tijd gedaan met een wat verouderde app waar weinig in aangepast kon worden. De vraag was of wij hier een applicatie voor konden maken welke interactief is. Dit is gedaan door eerst een aantal grafieken en tabellen te maken in aparte R scripts How to Detect Colors in OpenCV [Python] (n.d.). Dit zijn uiteindelijk 11 verschillende tabellen en grafieken geworden welke allemaal naar een ander onderdeel van de data kijken of het op een andere manier visualiseren. Deze scripts zijn hierna aangeroepen in een Shiny app. Shiny Shiny (n.d.) is een open source R package waarmee een applicatie gemaakt kan worden welke redelijk eenvoudig online gedeeld kan worden. De applicatie is te vinden op: Noldus V1.0 (n.d.) Hieronder geef ik een aantal screenshots van de werking van de Noldus applicatie: Als eerste kan de gewenste data ingeladen worden. Daarna is er een tab met algemene data, hieronder valt een tabel met wat metadata, een bargraph met de verdeling van mannelijke en vrouwelijke muizen in het experiment en een tabel met missende data. Vervolgens is er een tab met een interactieve grafiek met verschillende tijd gerelateerde grafieken per trial en een violin plot van de tijd per trial tussen de controle groep en de mutant, deze grafieken zijn interactief doordat de spreiding van de sessies zelf gekozen kan worden waardoor bijvoorbeeld alleen naar sessie 5-7 gekeken kan worden en doordat de tijd gerelateerde grafiek variabele gekozen kan worden. De volgende tab bevat een interactieve grafiek die de gemiddelde hoeveelheid percentage van de stap typen kan laten zien met dezelfde soort sessie spreiding als de vorige grafiek. Daarna is er een staaf diagram die het verschil tussen de controle groep en de mutant kan laten zien in de hoeveelheid percentage van de stappen per staptype en nogmaals de sessie spreiding. Als laatste is er een grafiek die de hoeveelheid percentage stappen visualiseerd als een viool grafiek met als interactie de keuze van staptype en de spreiding van de sessies. "],["computer-vision-morris-watermaze.html", "4 Computer vision morris watermaze", " 4 Computer vision morris watermaze Om te kunnen laten zien dat ik nieuwe bioinformatica skills kan leren heb ik 32 uur gestoken in het leren van computer vision. Ik ben al een tijd erg nieuwsgierig naar computer vision en de dingen die men er allemaal mee kan doen met betrekking tot de bioinformatica. Tijdens een gesprek met de begeleider van het project van Noldus kwam het onderwerp op computer vision, en wat zij er mee wilden bereiken. Hierbij kwam het gesprek ook op het morris watermaze waar Noldus ook mee heeft gewerkt, de data die hierbij is verkregen zou perfect zijn voor computer vision en deze filmpjes wouden ze ook wel naar mij doorsturen. In 2 jaar tijd zou ik nog veel beter willen worden in computer vision uitvoeren. Om hier beter in te worden is vooral meters maken een belangrijk aspect, dus een volgende stap zou zijn om nog meer en verschillende computer vision applicaties en scripts te maken. Mijn planning hiervoor is om de komende twee jaar elk half jaar in mijn vrije tijd voor een andere versie van computervision een applicatie te maken; bijvoorbeeld het eerste half jaar object detection, daarna hand gesture detection, vervolgens text detection en als laatste posture detection. Deze opties zouden wel in volgorde of volledig onderwerp kunnen veranderen naar gelang ik meer leer over computer vision of de limieten daarvan. Voor dit plan is dus al de eerste stap gezet voor het leren van computer vision met de eerder genoemde morris watermaze data die aangeleverd is door Noldus. Hieronder heb ik een computer vision blob detectie analyse uitgevoerd op morris watermaze data met behulp van opencv met python als codebase. Het morris watermaze is een grote bak met wit gekleurt water met daarin een klein tableau net onder de waterlijn waardoor het niet goed zichtbaar is. Hier worden over een paar dagen tijd ratten geleerd dat er een tableau is onder het water waar ze op kunnen staan en dus niet hoeven te zwemmen, dat vinden ze fijn en willen ze dus zo snel mogelijk bereiken. de manier waarop ze zoeken naar het tableau is interresant voor de onderzoekers. De analyse werd voorheen gedaan door de video af te spelen op een beeldscherm en daar dan een papier overheen te houden en dan de route van de rat overtekenen terwijl dit gebeurt. Dit is natuurlijk niet heel erg handig en kan sneller. Het doel van dit script is om ratten die in het water zitten automatisch te volgen met computer vision. Hiervoor wordt als eerste de video ingeladen waarna er een witte cirkel om de waterbak heen getekent wordt zodat de achtergrond niet interfereerd met de blob detectie OpenCV Python Tutorial #4 - Drawing (Lines, Images, Circles &amp; Text) (n.d.). Daarna moet de video van BGR naar HSV omgezet worden omdat de blob detectie niet werkt op bgr format OpenCV Python Tutorial #5 - Colors and Color Detection (n.d.). Daarna worden de uiterste kleuropties bepaald voor de mask die bepaald gaat worden HTML Color Picker (n.d.). De mask geeft een binaire video waar als de mask overeenkomt daar een 1 staat en het anders een 0 wordt OpenCV Python Tutorial #5 - Colors and Color Detection (n.d.). Hierna wordt er een blobdetectie op uitgevoerd waarbij het centrum van de blob gevonden wordt How to Detect Colors in OpenCV [Python] (n.d.) waarna hier een cirkel omheen getekent kan worden OpenCV: Contour Features (n.d.). Hierna wordt deze aangepaste video opgeslagen als .avi bestand Capture and Save Video Using OpenCV Python (n.d.). Dit kan dan het gemakkelijkst met VLC mediaplayer omgezet worden naar een .mp4 bestand How to Convert AVI to Mp4 Using VLC Media Player (n.d.) wat daarna embed kan worden in deze markdown Embed_video: Embed Video in R Markdown Documents in Mccarthy-m-g/Embedr: Embed Multimedia Files in HTML Documents (n.d.). Het volgende doel van dit experiment zou zijn om in plaats van een verplaatsende cirkel een blijvende lijn te tekenen zodat dit in 1 keer opgeslagen zou kunnen worden als .jpeg. import cv2 import numpy as np cap = cv2.VideoCapture(&#39;0115_LH39_d1_t4.mp4&#39;) # laad de video in out = cv2.VideoWriter(&#39;output.avi&#39;, cv2.VideoWriter_fourcc(*&#39;MJPG&#39;), 30.0, (int(cap.get(3)), int(cap.get(4)))) while True: # leest de afbeelding van de video ret, frame = cap.read() # teken een cirkel zodat de achtergrond niet wordt meegenomen in de mask img = cv2.circle(frame, (640,480), 660, (255,255,255), 400) # zet afbeelding om van bgr naar hsv zodat opencv er mee kan werken hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # bepaal de uiterste kleuren voor de mask dark_black = np.array([0, 0, 0]) light_black = np.array([0, 0, 60]) # de mask bepaalt welke kleuren in range zijn en maakt hier een binaire afbeelding van mask = cv2.inRange(hsv, dark_black, light_black) result = cv2.bitwise_and(frame, frame, mask=mask) # vind de contouren contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) if len(contours) !=0: for contour in contours: if cv2.contourArea(contour) &gt; 500: (x, y), radius = cv2.minEnclosingCircle(contour) center = (int(x), int(y)) radius = int(radius) cv2.circle(frame, center, radius, (0,255,0), 4) # sla de video op out.write(frame) # laat de video zien in een popup als watermaze result cv2.imshow(&#39;watermaze result&#39;, frame) # als je op q drukt sluit de loop vroegtijdig af if cv2.waitKey(1) == ord(&#39;q&#39;): break cap.release() out.release() cv2.destroyAllWindows() Hieronder is de input file te zien. Your browser does not support the video tag; for browser support, please see: https://www.w3schools.com/tags/tag_video.asp Hier is de output van de bovenstaande python code te zien. Your browser does not support the video tag; for browser support, please see: https://www.w3schools.com/tags/tag_video.asp "],["dosis-response-analyse.html", "5 Dosis response analyse", " 5 Dosis response analyse Hieronder wordt een dosis respons analyse uitgevoerd. Tijdens het kijken naar de data voor deze analyse valt op dat er wat datapunten missen in rij 192-196 en dat sommige kolommen volledig dezelfde data bevatten wat beter in een metadata bestand gezet had kunnen worden. Een stappenplan voor deze analyse is: 1. de ruwe data inlezen, 2. de data verkennen om te kijken of de data correct is ingelezen, 3. als er data verkeerd is deze aanpassen/ anders in laten lezen totdat deze wel correct is voor de analyse, 4. normaliseer de data met behulp van de negatieve controle, 5. visualiseer de data met behulp van ggplot, 6. trek conclusies aan de hand van de verkregen visualisatie. Als eerste wordt de data ingeladen in R. # inladen data data &lt;- read_excel(here( &quot;assignment_1&quot;, &quot;raw_data&quot;, &quot;CE.LIQ.FLOW.062_Tidydata.xlsx&quot; )) Hierna wordt van de ongefilterde data een scatterplot gemaakt om de data te ontdekken. # maak een scatterplot met de ongefilterde data data %&gt;% ggplot(aes(x= compConcentration, y= RawData, color= compName, shape= expType)) + geom_point() + theme(axis.text.x = element_text(angle =45, hjust = 1)) De data van de x-as is character in plaats van numeriek omdat het als wetenschappelijke notatie is geimporteerd, Dit moet aangepast worden. Hierna kan dezelfde grafiek nog een keer gemaakt worden maar dan met een logaritmische schaal op de x-as. # controleer de unieke waardes van de kolom compConcentration, hierin is te zien dat sommige waardes in wetenschappelijke notatie staan waardoor ze als character worden gelezen unique(data$compConcentration) ## [1] &quot;4.99&quot; &quot;0.499&quot; &quot;4.99E-2&quot; &quot;4.9899999999999996E-3&quot; &quot;4.9899999999999999E-4&quot; &quot;4.99E-5&quot; &quot;19.5&quot; ## [8] &quot;1.95&quot; &quot;0.19500000000000001&quot; &quot;1.95E-2&quot; &quot;1.9499999999999999E-3&quot; &quot;1.95E-4&quot; &quot;0,000195&quot; &quot;1.5&quot; ## [15] &quot;0&quot; &quot;0.5&quot; # verander de waardes met wetenschappelijke notatie naar normale notatie data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;1.95E-2&quot;] &lt;- &quot;0.0195&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;4.9899999999999996E-3&quot;] &lt;- &quot;0.0049899999999999996&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;4.9899999999999999E-4&quot;] &lt;- &quot;0.00049899999999999999&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;1.9499999999999999E-3&quot;] &lt;- &quot;0.0019499999999999999&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;4.99E-2&quot;] &lt;- &quot;0.0499&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;4.99E-5&quot;] &lt;- &quot;0.0000499&quot; data[&quot;compConcentration&quot;][data[&quot;compConcentration&quot;] == &quot;1.95E-4&quot;] &lt;- &quot;0.000195&quot; # verander de global options om geen wetenschappelijke notatie in de as.numeric function te hebben options(scipen=999) # controleer de unieke waardes nogmaals, de kolom kan nu omgezet worden naar numeriek unique(data$compConcentration) ## [1] &quot;4.99&quot; &quot;0.499&quot; &quot;0.0499&quot; &quot;0.0049899999999999996&quot; &quot;0.00049899999999999999&quot; &quot;0.0000499&quot; ## [7] &quot;19.5&quot; &quot;1.95&quot; &quot;0.19500000000000001&quot; &quot;0.0195&quot; &quot;0.0019499999999999999&quot; &quot;0.000195&quot; ## [13] &quot;0,000195&quot; &quot;1.5&quot; &quot;0&quot; &quot;0.5&quot; data$compConcentration &lt;- as.numeric(data$compConcentration) # verander de kolommen &quot;compName&quot; en &quot;expType&quot; naar een factor data$compName &lt;- as.factor(data$compName) data$expType &lt;- as.factor(data$expType) # maak een scatterplot me een beetje jitter zodat de punten niet overlappen data %&gt;% ggplot(aes(x= compConcentration, y= RawData, color= compName, shape= expType)) + geom_jitter(position = position_jitter(0.05)) + scale_x_log10(limits=c(0.01,100)) Allereerst moet deze data nog genormaliseert worden, Dit wordt gedaan door het gemiddelde van de negatieve controle naar 1 te zetten en alle andere waardes een verhouding daarvan te maken. Dit zodat er gekeken kan worden naar verhoudingen en niet naar absolute getallen. # verkrijg het gemiddelde van de controlNegative in de kolom expType norm &lt;- data %&gt;% group_by(expType) %&gt;% summarise_at(vars(RawData), list(name=mean)) # maak een nieuwe kolom met genormaliseerde data norm_data &lt;- data %&gt;% mutate(norm_RawData= RawData / as.numeric(norm[1,2])) # maak de genormaliseerde scatterplot norm_data %&gt;% ggplot(aes(x= compConcentration, y= norm_RawData, color= compName, shape= expType)) + geom_jitter(position = position_jitter(0.05)) + scale_x_log10(limits=c(0.01,100)) De positieve controle voor dit experiment is ethanol en de negatieve controle is S-medium. Als je naar de grafiek kijkt lijkt 2,6-diisopropylnaphtalene langzaam maar zeker af te nemen terwijl naphtalene lang hoog blijft en opeens afvalt en decane juist het omgekeerde doet en snel afvalt en daarna daar blijft hangen. Er lijkt dus wel een correlatie te zijn tussen de concentratie compound en de hoeveelheid getelde nematoden. "],["sql-data-analyse.html", "6 SQL data analyse", " 6 SQL data analyse Hieronder wordt een data analyse uitgevoerd met behulp van SQL. Er zijn drie datasets, de eerste is van de activiteit van de griep in verschillende landen gemeten op verschillende dagen, de tweede is dezelfde informatie maar dan voor de ziekte dengue. Als laatste wordt hier gebruik gemaakt van een bijgevoegde dataset van dslabs genaamd gapminder met algemene demografische informatie per land. Het doel is om de data in te laden in SQL, dat weer aan te vragen met een query en daarna te visualiseren met wat grafieken. Als eerste moet de data ingelezen worden, tidy gemaakt worden en er voor zorgen dat de datum gesplitst wordt over drie kolommen voor de verdere analyse. Daarna wordt het ook verkend om te controleren dat het inlezen goed is gegaan en de kolommen bijvoorbeeld de goede datatypes hebben. # lees de data in fluDf &lt;- read_csv(here(&quot;assignment_7&quot;, &quot;flu_data.csv&quot;), skip = 11) dengueDf &lt;- read_csv(here(&quot;assignment_7&quot;, &quot;dengue.csv&quot;), skip = 11) gapminderDf &lt;- data.frame(gapminder) # maak de griep en dengue data tidy want er zaten meerdere observaties op 1 rij tidyFlu &lt;- fluDf %&gt;% pivot_longer(cols=tail(colnames(fluDf), n= 29), names_to= &quot;country&quot;, values_to= &quot;fluActivity&quot;) tidyDengue &lt;- dengueDf %&gt;% pivot_longer(cols= tail(colnames(dengueDf), n= 10), names_to= &quot;country&quot;, values_to= &quot;dengueActivity&quot;) # maak de datatype voor de country en year kolommen hetzelfde over de verschillende tabellen gapminderDf$country &lt;- as.character(gapminderDf$country) tidyFlu &lt;- tidyFlu %&gt;% separate(col = Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) tidyDengue &lt;- tidyDengue %&gt;% separate(col = Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) # kijk of de datatypes nu overeenkomen en verken verder de data summary(tidyDengue) ## year month day country dengueActivity ## Length:6590 Length:6590 Length:6590 Length:6590 Min. :0.0000 ## Class :character Class :character Class :character Class :character 1st Qu.:0.0530 ## Mode :character Mode :character Mode :character Mode :character Median :0.1040 ## Mean :0.1390 ## 3rd Qu.:0.1755 ## Max. :1.0000 ## NA&#39;s :327 summary(tidyFlu) ## year month day country fluActivity ## Length:19111 Length:19111 Length:19111 Length:19111 Min. : 0.0 ## Class :character Class :character Class :character Class :character 1st Qu.: 37.0 ## Mode :character Mode :character Mode :character Mode :character Median : 185.0 ## Mean : 473.7 ## 3rd Qu.: 578.0 ## Max. :10555.0 ## NA&#39;s :1845 summary(gapminderDf) ## country year infant_mortality life_expectancy fertility population gdp continent region ## Length:10545 Min. :1960 Min. : 1.50 Min. :13.20 Min. :0.840 Min. : 31238 Min. : 40395128 Africa :2907 Western Asia :1026 ## Class :character 1st Qu.:1974 1st Qu.: 16.00 1st Qu.:57.50 1st Qu.:2.200 1st Qu.: 1333486 1st Qu.: 1845780110 Americas:2052 Eastern Africa : 912 ## Mode :character Median :1988 Median : 41.50 Median :67.54 Median :3.750 Median : 5009043 Median : 7794215003 Asia :2679 Western Africa : 912 ## Mean :1988 Mean : 55.31 Mean :64.81 Mean :4.084 Mean : 27014609 Mean : 147954410013 Europe :2223 Caribbean : 741 ## 3rd Qu.:2002 3rd Qu.: 85.10 3rd Qu.:73.00 3rd Qu.:6.000 3rd Qu.: 15231789 3rd Qu.: 55399648248 Oceania : 684 South America : 684 ## Max. :2016 Max. :276.90 Max. :83.90 Max. :9.220 Max. :1376048943 Max. :11744219459700 Southern Europe: 684 ## NA&#39;s :1453 NA&#39;s :187 NA&#39;s :185 NA&#39;s :2972 (Other) :5586 Hierna wordt de gecleande data opgeslagen als CSV en als RDS. # sla de gecleande data op write.csv(tidyFlu, file = here(&quot;assignment_7&quot;, &quot;tidyFlu.csv&quot;), row.names = FALSE) write.csv(tidyDengue, file = here(&quot;assignment_7&quot;, &quot;tidyDengue.csv&quot;)) write.csv(gapminderDf, file = here(&quot;assignment_7&quot;, &quot;gapminderDf.csv&quot;)) write_rds(tidyFlu, file = here(&quot;assignment_7&quot;, &quot;tidyFlu.rds&quot;)) write_rds(tidyDengue, file = here(&quot;assignment_7&quot;, &quot;tidyDengue.rds&quot;)) write_rds(gapminderDf, file = here(&quot;assignment_7&quot;, &quot;gapminderDf.rds&quot;)) Nu wordt er een con object gemaakt wat niet included is in de html zodat men online mijn wachtwoord niet ziet. Daarna worden de CSVs geupload naar de SQL server. # laad de tabellen in de database in dbWriteTable(con, &quot;tidyFlu&quot;, read_csv(here(&quot;assignment_7&quot;, &quot;tidyFlu.csv&quot;)), overwrite = TRUE) dbWriteTable(con, &quot;tidyDengue&quot;, read_csv(here(&quot;assignment_7&quot;, &quot;tidyDengue.csv&quot;)), overwrite = TRUE) dbWriteTable(con, &quot;gapminderDf&quot;, read_csv(here(&quot;assignment_7&quot;, &quot;gapminderDf.csv&quot;)), overwrite = TRUE) Vervolgens wordt er wat verkennende data aangevraagd aan de database om te controleren dat de data goed is over gekomen waarna het uiteindelijk gejoined opgevraagd wordt vanuit de server. # laat de namen van de verschillende tabellen in de database zien dbListTables(con) ## [1] &quot;tidyFlu&quot; &quot;tidyDengue&quot; &quot;gapminderDf&quot; # laat de namen van de kolommen van de verschillende tabellen zien dbListFields(con, dbListTables(con)[1]) ## [1] &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;country&quot; &quot;fluActivity&quot; dbListFields(con, dbListTables(con)[2]) ## [1] &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;country&quot; &quot;dengueActivity&quot; dbListFields(con, dbListTables(con)[3]) ## [1] &quot;country&quot; &quot;year&quot; &quot;infant_mortality&quot; &quot;life_expectancy&quot; &quot;fertility&quot; &quot;population&quot; &quot;gdp&quot; &quot;continent&quot; ## [9] &quot;region&quot; # geef een summary van alle tabellen in de database summary(dbReadTable(con, dbListTables(con)[1])) ## year month day country fluActivity ## Min. :2002 Length:19111 Length:19111 Length:19111 Min. : 0.0 ## 1st Qu.:2006 Class :character Class :character Class :character 1st Qu.: 37.0 ## Median :2009 Mode :character Mode :character Mode :character Median : 185.0 ## Mean :2009 Mean : 473.7 ## 3rd Qu.:2012 3rd Qu.: 578.0 ## Max. :2015 Max. :10555.0 ## NA&#39;s :1845 summary(dbReadTable(con, dbListTables(con)[2])) ## year month day country dengueActivity ## Min. :2002 Length:6590 Length:6590 Length:6590 Min. :0.0000 ## 1st Qu.:2006 Class :character Class :character Class :character 1st Qu.:0.0530 ## Median :2009 Mode :character Mode :character Mode :character Median :0.1040 ## Mean :2009 Mean :0.1390 ## 3rd Qu.:2012 3rd Qu.:0.1755 ## Max. :2015 Max. :1.0000 ## NA&#39;s :327 summary(dbReadTable(con, dbListTables(con)[3])) ## country year infant_mortality life_expectancy fertility population gdp continent region ## Length:10545 Min. :1960 Min. : 1.50 Min. :13.20 Min. :0.840 Min. : 31238 Min. : 40395128 Length:10545 Length:10545 ## Class :character 1st Qu.:1974 1st Qu.: 16.00 1st Qu.:57.50 1st Qu.:2.200 1st Qu.: 1333486 1st Qu.: 1845780110 Class :character Class :character ## Mode :character Median :1988 Median : 41.50 Median :67.54 Median :3.750 Median : 5009043 Median : 7794215003 Mode :character Mode :character ## Mean :1988 Mean : 55.31 Mean :64.81 Mean :4.084 Mean : 27014609 Mean : 147954410013 ## 3rd Qu.:2002 3rd Qu.: 85.10 3rd Qu.:73.00 3rd Qu.:6.000 3rd Qu.: 15231789 3rd Qu.: 55399648248 ## Max. :2016 Max. :276.90 Max. :83.90 Max. :9.220 Max. :1376048943 Max. :11744219459700 ## NA&#39;s :1453 NA&#39;s :187 NA&#39;s :185 NA&#39;s :2972 # join de gapminder tabel met de tidyflu tabel joined &lt;- dbGetQuery(con, &quot;SELECT * FROM \\&quot;gapminderDf\\&quot; INNER JOIN \\&quot;tidyFlu\\&quot; ON \\&quot;gapminderDf\\&quot;.year = \\&quot;tidyFlu\\&quot;.year AND \\&quot;gapminderDf\\&quot;.country = \\&quot;tidyFlu\\&quot;.country&quot;) Uiteindelijk wordt de opgevraagde gejoinde data gebruikt om een paar visualisaties van de data mee te doen. Als eerste is er een box plot met op de y-as de levensverwachting in jaren en dit is gegroepeert per regio. De volgende is een lijngrafiek met op de y-as de kindersterfte per duizend kinderen in Argentinië en op de x-as de jaren waarop dit gemeten is. De laatste grafiek is een cirkel diagram met de BBP opgeteld per continent. joined %&gt;% ggplot(aes(color = region, y = life_expectancy)) + geom_boxplot() + labs(title = &quot;Levensverwachting per regio&quot;, y = &quot;Levensverwachting in jaren&quot;, color = &quot;Regio&#39;s&quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) joined %&gt;% filter(country == &quot;Argentina&quot;) %&gt;% ggplot(aes(x = year, y = infant_mortality)) + geom_line() + scale_x_continuous(breaks = seq(2000,2020,1)) + scale_y_continuous(breaks = seq(10,20,1)) + labs(title = &quot;Kindersterfte per jaar in Argentinië&quot;, x = &quot;Jaren&quot;, y = &quot;Kindersterfte per duizend kinderen&quot;) joined %&gt;% ggplot(aes(x = &quot;&quot;, y = gdp, fill = continent)) + geom_col() + coord_polar(theta = &quot;y&quot;) + theme_void() + labs(title = &quot;Verhouding BBP per continent&quot;, fill = &quot;Continent&quot;) "],["zelfgemaakte-package.html", "7 Zelfgemaakte package", " 7 Zelfgemaakte package Hieronder is een zelfgemaakte package te zien die ook te downloaden en proberen is. Voor de package zie repository: explorers op profile: WouterVerra, zie ook de soccer dataset die bijgevoegd is aan de package. devtools::install_github(&quot;WouterVerra/explorers&quot;, build_vignettes = TRUE, force = TRUE) # laad de package library(explorers) # standaard toegevoegde data soccer # explore functie explore(soccer) ## [[1]] ## [1] &quot;class:&quot; ## ## [[2]] ## [1] &quot;data.frame&quot; ## ## [[3]] ## [1] &quot;columns:&quot; ## ## [[4]] ## [1] &quot;points&quot; &quot;assists&quot; &quot;team&quot; ## ## [[5]] ## [1] &quot;dimensions:&quot; ## ## [[6]] ## [1] 6 3 ## ## [[7]] ## [1] &quot;summary:&quot; ## ## [[8]] ## points assists team ## Min. :2.0 Min. :6.00 Length:6 ## 1st Qu.:3.0 1st Qu.:6.75 Class :character ## Median :3.5 Median :7.00 Mode :character ## Mean :4.0 Mean :7.25 ## 3rd Qu.:4.0 3rd Qu.:7.50 ## Max. :8.0 Max. :9.00 ## NA&#39;s :2 # NAcol functie NAcol(soccer) ## [1] &quot;points = 0&quot; ## [1] &quot;assists = 2&quot; ## [1] &quot;team = 1&quot; # NArow functie NArow(soccer) ## [1] &quot;2 = 1&quot; ## [1] &quot;4 = 2&quot; # replace functie replace(soccer, &quot;points&quot;, 3, 20) De HTML vignette is hieronder te zien, ook is het mogelijk om een uitleg van alle functies op te zoeken door bijvoorbeeld ?replace in de console te typen. "],["parameterizatie-van-rmarkdown-documenten.html", "8 Parameterizatie van Rmarkdown documenten", " 8 Parameterizatie van Rmarkdown documenten Dit is een Rmarkdown bestand met parameters waardoor snel en overzichtelijk verschillende outputs gemaakt kunnen worden. Het gebruik van parameters wordt gepresenteerd met dit voorbeeld van covid 19 data die gedownload is van de ECDC Download COVID-19 Data Sets (2020). Als eerste worden in de YAML header parameters toegevoegd die daarna in de code gecalled kunnen worden waardoor alleen in de YAML header de informatie aangepast hoeft te worden en het overal in het bestand wordt overgenomen. Dit is veel mmakkelijker en met minder kans op menselijke fouten dan meerdere calls in de code aanpassen. Daarna wordt de data ingelezen, meerdere malen gefilterd op verschillende parameters en daarna met ggplot geplot. De eerste plot geeft de hoeveelheid cases van covid 19 in de dagen van de geselecteerde maand in de het geselecteerde jaar in het geselecteerde land. De tweede grafiek geeft de hoeveelheid covid gerelateerde sterfgevallen in de dagen van de geselecteerde maand in de het geselecteerde jaar in het geselecteerde land # read in csv with covid data covid_data &lt;- read.csv(here(&quot;assignment_9&quot;, &quot;data.csv&quot;)) # filter op land covid_data &lt;- covid_data %&gt;% filter(countriesAndTerritories == params$country) # filter op jaar covid_data &lt;- covid_data %&gt;% filter(year == params$year) # filter op maand covid_data &lt;- covid_data %&gt;% filter(month == params$month) # plot the cases covid_data %&gt;% ggplot(aes(x= day, y= cases)) + geom_line() + geom_point() + labs(title= paste0(&quot;Covid 19 cases in: &quot;, params$country, &quot; in: &quot;, params$month, &quot;/&quot;, params$year), y= &quot;Covid cases&quot;) # plot the deaths covid_data %&gt;% ggplot(aes(x= day, y= deaths)) + geom_line() + geom_point() + labs(title= paste0(&quot;Covid 19 deaths in: &quot;, params$country, &quot; in: &quot;, params$month, &quot;/&quot;, params$year), y= &quot;Covid deaths&quot;) "],["bibliografie.html", "9 Bibliografie", " 9 Bibliografie "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
